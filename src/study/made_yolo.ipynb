{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c447385f",
   "metadata": {},
   "source": [
    "### Yolo Architecture (Architecture; êµ¬ì„± ìš”ì†Œ, ë™ì‘ ì›ë¦¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae12c25",
   "metadata": {},
   "source": [
    "YOLO model êµ¬í˜„ (ë‹¤ë¥¸ ë°©í–¥ì—ì„œ ì ‘ê·¼í•œ ì½”ë“œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81d361",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1. YOLOv5 Backbone êµ¬í˜„ (ë…¼ë¬¸ ê¸°ë°˜)\n",
    "- ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ì—ˆì„ ë•Œ \"íŠ¹ì§• ì¶”ì¶œ(feature extraction)\" í•˜ëŠ” ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f551c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 1-1. í™˜ê²½ ì„¸íŒ…\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ì¥ì¹˜ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ… Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09892825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ shape: torch.Size([1, 32, 320, 320])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 1-2. Focus ëª¨ë“ˆ\n",
    "# ============================================================\n",
    "\n",
    "class Focus(nn.Module):\n",
    "    \"\"\"\n",
    "    ğŸ”¹ ë…¼ë¬¸ ê¸°ë°˜ ì„¤ëª…:\n",
    "        - YOLOv5ì€ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ stride=2 Convë¡œ ì¤„ì´ì§€ ì•Šê³ ,\n",
    "          2x2 ì˜ì—­ì„ ì±„ë„ ë°©í–¥ìœ¼ë¡œ í•©ì³ ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”.\n",
    "        - ì¦‰, (H, W) â†’ (H/2, W/2) ëŒ€ì‹ , ì±„ë„(3â†’12)ë¡œ í™•ì¥ í›„ Conv.\n",
    "\n",
    "    ğŸ”¹ ì´ìœ :\n",
    "        - ê³µê°„ì •ë³´(spatial feature)ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì—°ì‚° íš¨ìœ¨ì„±ì„ ë†’ì„.\n",
    "        - ì‘ì€ ë¬¼ì²´ì˜ ìœ„ì¹˜ ì†ì‹¤ì„ ì¤„ì„.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, out_channels=32, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels * 4, out_channels, kernel_size, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 4ê°œ íŒ¨ì¹˜ë¡œ ë‚˜ëˆ  ì±„ë„ë°©í–¥ìœ¼ë¡œ ê²°í•©\n",
    "        patch = torch.cat([\n",
    "            x[..., ::2, ::2],\n",
    "            x[..., 1::2, ::2],\n",
    "            x[..., ::2, 1::2],\n",
    "            x[..., 1::2, 1::2]\n",
    "        ], dim=1)\n",
    "        return self.conv(patch)\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "x = torch.randn(1, 3, 640, 640)\n",
    "focus = Focus()\n",
    "y = focus(x)\n",
    "print(\"ì¶œë ¥ shape:\", y.shape)  # (1, 32, 320, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ce9706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ shape: torch.Size([1, 64, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 1-3. Conv ë¸”ë¡\n",
    "# ============================================================\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "block = Conv(32, 64, 3, 2)\n",
    "out = block(torch.randn(1, 32, 320, 320))\n",
    "print(\"ì¶œë ¥ shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e4f2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ shape: torch.Size([1, 64, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 1-4. Bottleneck ë¸”ë¡\n",
    "# ============================================================\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    ğŸ”¹ ë‚´ë¶€ êµ¬ì¡°:\n",
    "        1x1 Conv â†’ 3x3 Conv (Residual ì—°ê²°)\n",
    "    ğŸ”¹ ì´ìœ :\n",
    "        - 1x1 Convë¡œ ì±„ë„ ì¶•ì†Œ í›„ 3x3 Convë¡œ ë³µì› â†’ ì—°ì‚° íš¨ìœ¨ì„±\n",
    "        - Skip ì—°ê²°ë¡œ gradient íë¦„ ê°œì„  (ResNet ì•„ì´ë””ì–´)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, shortcut=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv(in_channels, out_channels, 1, 1)\n",
    "        self.conv2 = Conv(out_channels, out_channels, 3, 1)\n",
    "        self.use_add = shortcut and in_channels == out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv2(self.conv1(x))\n",
    "        return x + y if self.use_add else y\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "bottle = Bottleneck(64, 64)\n",
    "out = bottle(torch.randn(1, 64, 160, 160))\n",
    "print(\"ì¶œë ¥ shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6966fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ shape: torch.Size([1, 128, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 1-5. CSPBlock (Cross Stage Partial)\n",
    "# ============================================================\n",
    "\n",
    "class CSPBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ğŸ”¹ êµ¬ì¡°:\n",
    "        ì…ë ¥ â†’ ë‘ ê²½ë¡œë¡œ ë¶„í• \n",
    "          - í•œìª½ì€ Bottleneck ë°˜ë³µ\n",
    "          - ë‹¤ë¥¸ í•œìª½ì€ identity\n",
    "        ì´í›„ concat â†’ Conv â†’ ì¶œë ¥\n",
    "    ğŸ”¹ ì´ìœ :\n",
    "        - ì¤‘ë³µ gradient íë¦„ ë°©ì§€ (feature redundancy ê°ì†Œ)\n",
    "        - ì„±ëŠ¥ ìœ ì§€í•˜ë©´ì„œ ì—°ì‚°ëŸ‰ ê°ì†Œ\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_blocks=1):\n",
    "        super().__init__()\n",
    "        hidden = out_channels // 2\n",
    "        self.conv1 = Conv(in_channels, hidden, 1, 1)\n",
    "        self.conv2 = Conv(in_channels, hidden, 1, 1)\n",
    "        self.blocks = nn.Sequential(*[Bottleneck(hidden, hidden) for _ in range(num_blocks)])\n",
    "        self.conv3 = Conv(2 * hidden, out_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.blocks(self.conv1(x))\n",
    "        y2 = self.conv2(x)\n",
    "        out = torch.cat((y1, y2), dim=1)\n",
    "        return self.conv3(out)\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "csp = CSPBlock(64, 128, num_blocks=2)\n",
    "out = csp(torch.randn(1, 64, 160, 160))\n",
    "print(\"ì¶œë ¥ shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66035aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 1-6. YOLOv5 Backbone êµ¬ì„± (multi-sclae ì¶œë ¥)\n",
    "# ============================================================\n",
    "\n",
    "class YOLOBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.focus = Focus(3, 32)\n",
    "        self.conv1 = Conv(32, 64, 3, 2)\n",
    "        self.csp1 = CSPBlock(64, 128, 3)\n",
    "        self.csp2 = CSPBlock(128, 256, 9)\n",
    "        self.csp3 = CSPBlock(256, 512, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.focus(x)           # (32, 320, 320)\n",
    "        x = self.conv1(x)           # (64, 160, 160)\n",
    "        c1 = self.csp1(x)           # (128, 160, 160)\n",
    "        c2 = self.csp2(c1)          # (256, 80, 80)\n",
    "        c3 = self.csp3(c2)          # (512, 40, 40)\n",
    "        return c1, c2, c3           # 3ê°œ feature map ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce0861",
   "metadata": {},
   "source": [
    "### Step 2. YOLOv5 Neck + Head êµ¬í˜„\n",
    "- Neck (PANet êµ¬ì¡°)\n",
    "  - Backbone ì—ì„œ ì¶”ì¶œí•œ ë‹¤ì–‘í•œ í¬ê¸°ì˜ feature map ì„ ì—°ê²°\n",
    "  - ì‘ì€ ë¬¼ì²´ë¶€í„° í° ë¬¼ì²´ê¹Œì§€ ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì„ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "  - FPN + PANet êµ¬ì¡°ë¥¼ ê²°í•©í•˜ì—¬ ì •ë³´ê°€ ìœ„ì•„ë˜ë¡œ íë¦„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aec1788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPN ì¶œë ¥: torch.Size([1, 256, 40, 40])\n",
      "PAN ì¶œë ¥: torch.Size([1, 512, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 2-1. Neck (PANet êµ¬ì¡°)\n",
    "# ============================================================\n",
    "\n",
    "class YOLOv5Neck(nn.Module):\n",
    "    \"\"\"\n",
    "    ğŸ”¹ ë…¼ë¬¸ ê¸°ë°˜ ì„¤ëª…:\n",
    "        - YOLOv5ì˜ Neckì€ FPN(Feature Pyramid Network)ê³¼ PANet(Path Aggregation Network)ì˜\n",
    "          ì¥ì ì„ ê²°í•©í•œ êµ¬ì¡°.\n",
    "        - FPN: ìƒìœ„ ê³„ì¸µì˜ semantic featureë¥¼ í•˜ìœ„ë¡œ ì „ë‹¬.\n",
    "        - PANet: í•˜ìœ„ ê³„ì¸µì˜ localization featureë¥¼ ìƒìœ„ë¡œ ì „ë‹¬.\n",
    "\n",
    "    ğŸ”¹ ì´ìœ :\n",
    "        - ì„œë¡œ ë‹¤ë¥¸ ìŠ¤ì¼€ì¼ì˜ ë¬¼ì²´ë¥¼ ê°ì§€í•˜ê¸° ìœ„í•´ ë‹¤ì¤‘ feature mapì„ ê²°í•©.\n",
    "        - ì‘ì€ ë¬¼ì²´(ê³ í•´ìƒë„ feature)ì™€ í° ë¬¼ì²´(ì €í•´ìƒë„ feature) ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=[128, 256, 512]):\n",
    "        super().__init__()\n",
    "        c1, c2, c3 = channels\n",
    "\n",
    "        # FPN\n",
    "        self.conv1 = Conv(c3, c2, 1, 1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.csp_topdown = CSPBlock(c2 + c2, c2, num_blocks=3)\n",
    "\n",
    "        # PANet\n",
    "        self.conv2 = Conv(c2, c1, 1, 1)\n",
    "        self.downsample = Conv(c1, c2, 3, 2)\n",
    "        self.csp_bottomup = CSPBlock(c2 + c3, c3, num_blocks=3)\n",
    "\n",
    "    def forward(self, x_small, x_medium, x_large):\n",
    "        # FPN (Top-down)\n",
    "        up = self.upsample(self.conv1(x_large))\n",
    "        if up.shape != x_medium.shape:  # ìë™ í¬ê¸° ë³´ì •\n",
    "            up = F.interpolate(up, size=x_medium.shape[-2:], mode='nearest')\n",
    "        merge1 = torch.cat([up, x_medium], dim=1)\n",
    "        fpn_out = self.csp_topdown(merge1)\n",
    "\n",
    "        # PANet (Bottom-up)\n",
    "        down = self.downsample(self.conv2(fpn_out))\n",
    "        if down.shape != x_large.shape:\n",
    "            down = F.interpolate(down, size=x_large.shape[-2:], mode='nearest')\n",
    "        merge2 = torch.cat([down, x_large], dim=1)\n",
    "        pan_out = self.csp_bottomup(merge2)\n",
    "\n",
    "        return fpn_out, pan_out\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "x_small = torch.randn(1, 128, 80, 80)\n",
    "x_medium = torch.randn(1, 256, 40, 40)\n",
    "x_large = torch.randn(1, 512, 20, 20)\n",
    "neck = YOLOv5Neck()\n",
    "f1, f2 = neck(x_small, x_medium, x_large)\n",
    "print(\"FPN ì¶œë ¥:\", f1.shape)\n",
    "print(\"PAN ì¶œë ¥:\", f2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce28845",
   "metadata": {},
   "source": [
    "Head\n",
    "- Neck ì—ì„œ í†µí•©ëœ feature ë¥¼ ì…ë ¥ë°›ì•„ (x, y, w, h, confidence, class) ì˜ˆì¸¡\n",
    "- ê° ìŠ¤ì¼€ì¼ë§ˆë‹¤ anchor ê¸°ë°˜ ì˜ˆì¸¡ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed31d006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¤ì¼€ì¼ 1 ì¶œë ¥: torch.Size([1, 3, 8, 80, 80])\n",
      "ìŠ¤ì¼€ì¼ 2 ì¶œë ¥: torch.Size([1, 3, 8, 40, 40])\n",
      "ìŠ¤ì¼€ì¼ 3 ì¶œë ¥: torch.Size([1, 3, 8, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 2-2. Detection Head\n",
    "# ============================================================\n",
    "\n",
    "class YOLOv5Head(nn.Module):\n",
    "    \"\"\"\n",
    "    ğŸ”¹ ë…¼ë¬¸ ê¸°ë°˜ ì„¤ëª…:\n",
    "        - ê° ìŠ¤ì¼€ì¼ featureì—ì„œ anchor boxë§ˆë‹¤ (x, y, w, h, conf, class) ì˜ˆì¸¡.\n",
    "        - sigmoid í™œì„±í•¨ìˆ˜ë¡œ ê° ê°’ì„ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”.\n",
    "\n",
    "    ğŸ”¹ ì´ìœ :\n",
    "        - x, y: ì…€(grid) ë‚´ ìƒëŒ€ ì¢Œí‘œ (sigmoid)\n",
    "        - w, h: anchor box ë¹„ìœ¨ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§ (exp or sigmoid)\n",
    "        - conf: ë¬¼ì²´ ì¡´ì¬ í™•ë¥ \n",
    "        - class: softmax ë˜ëŠ” sigmoidë¡œ í´ë˜ìŠ¤ í™•ë¥  ì˜ˆì¸¡\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=[128, 256, 512], num_classes=3, num_anchors=3):\n",
    "        super().__init__()\n",
    "        self.detect_layers = nn.ModuleList()\n",
    "        for c in channels:\n",
    "            self.detect_layers.append(\n",
    "                nn.Conv2d(c, num_anchors * (5 + num_classes), 1)\n",
    "            )\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "\n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        features: neckì—ì„œ ë‚˜ì˜¨ ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ feature map list\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for i, f in enumerate(features):\n",
    "            pred = self.detect_layers[i](f)\n",
    "            B, _, H, W = pred.shape\n",
    "            pred = pred.view(B, self.num_anchors, 5 + self.num_classes, H, W)\n",
    "            outputs.append(pred)\n",
    "            print(f\"ìŠ¤ì¼€ì¼ {i+1} ì¶œë ¥:\", pred.shape)\n",
    "        return outputs\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "features = [torch.randn(1, 128, 80, 80),\n",
    "            torch.randn(1, 256, 40, 40),\n",
    "            torch.randn(1, 512, 20, 20)]\n",
    "head = YOLOv5Head(num_classes=3)\n",
    "outputs = head(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59489ad5",
   "metadata": {},
   "source": [
    "YOLOv5 ì „ì²´ êµ¬ì¡° ê²°í•© (Backbone + Neck + Head)\n",
    "- ì „ì²´ êµ¬ì¡°ë¥¼ ì—°ê²°í•´ì„œ ì…ë ¥ -> feature ì¶”ì¶œ -> multi-scale ì˜ˆì¸¡ê¹Œì§€ ì™„ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2303a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ¤ì¼€ì¼ 1 ì¶œë ¥: torch.Size([1, 3, 8, 160, 160])\n",
      "ìŠ¤ì¼€ì¼ 2 ì¶œë ¥: torch.Size([1, 3, 8, 160, 160])\n",
      "ìŠ¤ì¼€ì¼ 3 ì¶œë ¥: torch.Size([1, 3, 8, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ§© Step 2-3. YOLOv5 ì „ì²´ ëª¨ë¸ ê²°í•©\n",
    "# ============================================================\n",
    "\n",
    "class YOLOv5Model(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.backbone = YOLOBackbone()\n",
    "        self.neck = YOLOv5Neck()\n",
    "        self.head = YOLOv5Head(num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Backbone â†’ 3ê°œì˜ feature map ì¶œë ¥\n",
    "        c1, c2, c3 = self.backbone(x)\n",
    "\n",
    "        # Neck\n",
    "        fpn_out, pan_out = self.neck(c1, c2, c3)\n",
    "\n",
    "        # Head\n",
    "        outputs = self.head([c1, fpn_out, pan_out])\n",
    "        return outputs\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸\n",
    "x = torch.randn(1, 3, 640, 640)\n",
    "model = YOLOv5Model(num_classes=3)\n",
    "outputs = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad9f4dc",
   "metadata": {},
   "source": [
    "---\n",
    "3ï¸âƒ£\tí•™ìŠµ ë° í‰ê°€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\tdataset loader, loss, optimizer, metrics\tì‹¤ì œ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨/ê²€ì¦ ìˆ˜í–‰\n",
    "\n",
    "4ï¸âƒ£\tê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\tPrecision, Recall, mAP, confusion matrix\të…¼ë¬¸ ìˆ˜ì¤€ì˜ ê²°ê³¼ ì¬í˜„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
