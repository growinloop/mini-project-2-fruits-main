{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4060b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, cv2, torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "# YOLOv5\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# EfficientDet\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "\n",
    "# COCO API\n",
    "try:\n",
    "    from pycocotools.coco import COCO\n",
    "    from pycocotools.cocoeval import COCOeval\n",
    "    COCO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"pycocotools 없음\")\n",
    "    COCO_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af46dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BASE_DIR: c:\\Github\\mini-project-2-fruits\n",
      " IMG_DIR: c:\\Github\\mini-project-2-fruits\\data\\raw\\images\n",
      " JSON_DIR: c:\\Github\\mini-project-2-fruits\\data\\raw\\json_labels\n",
      " DATASET_YOLO: c:\\Github\\mini-project-2-fruits\\processed\\preprocessed_data\\yolov5\n",
      " DATASET_EFFDET: c:\\Github\\mini-project-2-fruits\\processed\\preprocessed_data\\efficientdet\n",
      " RESULT_DIR: c:\\Github\\mini-project-2-fruits\\processed\\results_comparison\n"
     ]
    }
   ],
   "source": [
    "# 경로 설정\n",
    "BASE_DIR = Path.cwd().parent\n",
    "IMG_DIR = BASE_DIR / \"data/raw/images\"\n",
    "JSON_DIR = BASE_DIR / \"data/raw/json_labels\"\n",
    "DATASET_YOLO = BASE_DIR / \"processed/preprocessed_data/yolov5\"\n",
    "DATASET_EFFDET = BASE_DIR / \"processed/preprocessed_data/efficientdet\"\n",
    "RESULT_DIR = BASE_DIR / \"processed/results_comparison\"\n",
    "YOLO_WEIGHTS_FILE = RESULT_DIR / \"yolov5su.pt\"\n",
    "\n",
    "print(f\" BASE_DIR: {BASE_DIR}\")\n",
    "print(f\" IMG_DIR: {IMG_DIR}\")\n",
    "print(f\" JSON_DIR: {JSON_DIR}\")     \n",
    "print(f\" DATASET_YOLO: {DATASET_YOLO}\")      \n",
    "print(f\" DATASET_EFFDET: {DATASET_EFFDET}\")\n",
    "print(f\" RESULT_DIR: {RESULT_DIR}\")\n",
    "\n",
    "for d in [DATASET_YOLO, DATASET_EFFDET, RESULT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7624dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글 폰트 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 한국어 폰트\n",
    "def setup_korean_font():\n",
    "    try:\n",
    "        if os.name == 'nt':\n",
    "            font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "            if os.path.exists(font_path):\n",
    "                font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "                plt.rc('font', family=font_name)\n",
    "            else:\n",
    "                plt.rc('font', family='DejaVu Sans')\n",
    "        elif os.name == 'posix':\n",
    "            plt.rc('font', family='AppleGothic')\n",
    "        \n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "        print(\"한글 폰트 설정 완료\")\n",
    "    except Exception as e:\n",
    "        print(f\"폰트 설정 실패: {e}\")\n",
    "        plt.rc('font', family='DejaVu Sans')\n",
    "\n",
    "setup_korean_font()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37675506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def preprocess_data():\n",
    "    jsons = list(JSON_DIR.glob(\"*.json\"))\n",
    "    if not jsons:\n",
    "        return {}, []\n",
    "    \n",
    "    train, temp = train_test_split(jsons, train_size=0.8, random_state=42)\n",
    "    val, test = train_test_split(temp, train_size=0.5, random_state=42)\n",
    "    splits = {'train': [], 'val': [], 'test': []}\n",
    "    classes, class_to_idx = [], {}\n",
    "    \n",
    "    for split, files in zip(['train', 'val', 'test'], [train, val, test]):\n",
    "        for j in tqdm(files, desc=f\"Loading {split}\"):\n",
    "            with open(j, 'r', encoding='utf-8') as f:\n",
    "                d = json.load(f)\n",
    "            \n",
    "            # 이미지 찾기\n",
    "            img_path = None\n",
    "            for ext in ['.jpg', '.png', '.jpeg', '.JPG', '.PNG', '.JPEG']:\n",
    "                p = IMG_DIR / f\"{j.stem}{ext}\"\n",
    "                if p.exists():\n",
    "                    img_path = str(p)\n",
    "                    break\n",
    "            if not img_path:\n",
    "                continue\n",
    "            \n",
    "            # 클래스\n",
    "            name = f\"{d['cate1']}_{d['cate3']}\"\n",
    "            if name not in classes:\n",
    "                class_to_idx[name] = len(classes)\n",
    "                classes.append(name)\n",
    "            \n",
    "            bbox = d['bndbox']\n",
    "            splits[split].append({\n",
    "                'image': img_path,\n",
    "                'bbox': [bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']],\n",
    "                'label': class_to_idx[name],\n",
    "                'json_stem': j.stem\n",
    "            })\n",
    "    \n",
    "    print(f\"Dataset: train={len(splits['train'])}, val={len(splits['val'])}, test={len(splits['test'])}\")\n",
    "    return splits, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63cf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO datasets\n",
    "def prepare_yolo_dataset(splits, classes):\n",
    "    import yaml\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        (DATASET_YOLO / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "        (DATASET_YOLO / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for split, items in splits.items():\n",
    "        for item in tqdm(items, desc=f\"YOLO {split}\"):\n",
    "            with open(item['image'], 'rb') as f:\n",
    "                img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "            h, w = img.shape[:2]\n",
    "            \n",
    "            img_save = DATASET_YOLO / 'images' / split / f\"{item['json_stem']}.jpg\"\n",
    "            cv2.imwrite(str(img_save), img)\n",
    "            \n",
    "            bbox = item['bbox']\n",
    "            x_center = (bbox[0] + bbox[2]) / 2 / w\n",
    "            y_center = (bbox[1] + bbox[3]) / 2 / h\n",
    "            width = (bbox[2] - bbox[0]) / w\n",
    "            height = (bbox[3] - bbox[1]) / h\n",
    "            \n",
    "            label_save = DATASET_YOLO / 'labels' / split / f\"{item['json_stem']}.txt\"\n",
    "            with open(label_save, 'w') as f:\n",
    "                f.write(f\"{item['label']} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "    \n",
    "    with open(DATASET_YOLO / 'data.yaml', 'w', encoding='utf-8') as f:\n",
    "        yaml.dump({\n",
    "            'path': str(DATASET_YOLO),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'test': 'images/test',\n",
    "            'nc': len(classes),\n",
    "            'names': classes\n",
    "        }, f, allow_unicode=True)\n",
    "    \n",
    "    print(f\"YOLO 데이터셋 준비 완료: {DATASET_YOLO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03bd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientDet 데이터셋\n",
    "class EffDetDataset(Dataset):\n",
    "    def __init__(self, data, img_size=512):\n",
    "        self.data = data\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        with open(item['image'], 'rb') as f:\n",
    "            img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        bbox = item['bbox']\n",
    "        bbox_scaled = [\n",
    "            bbox[0] * self.img_size / w,\n",
    "            bbox[1] * self.img_size / h,\n",
    "            bbox[2] * self.img_size / w,\n",
    "            bbox[3] * self.img_size / h\n",
    "        ]\n",
    "        \n",
    "        return img_tensor, {\n",
    "            'bbox': torch.tensor([bbox_scaled], dtype=torch.float32),\n",
    "            'cls': torch.tensor([item['label']], dtype=torch.long),\n",
    "            'img_scale': torch.tensor([1.0], dtype=torch.float32),\n",
    "            'img_size': torch.tensor([self.img_size, self.img_size], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = torch.stack([x[0] for x in batch])\n",
    "    max_boxes = max([x[1]['bbox'].shape[0] for x in batch])\n",
    "    \n",
    "    bboxes, classes, scales, sizes = [], [], [], []\n",
    "    for x in batch:\n",
    "        bbox, cls = x[1]['bbox'], x[1]['cls']\n",
    "        n = bbox.shape[0]\n",
    "        if n < max_boxes:\n",
    "            bbox = torch.cat([bbox, torch.zeros((max_boxes - n, 4))])\n",
    "            cls = torch.cat([cls, torch.ones(max_boxes - n, dtype=torch.long) * -1])\n",
    "        bboxes.append(bbox)\n",
    "        classes.append(cls)\n",
    "        scales.append(x[1]['img_scale'])\n",
    "        sizes.append(x[1]['img_size'])\n",
    "    \n",
    "    return images, {\n",
    "        'bbox': torch.stack(bboxes),\n",
    "        'cls': torch.stack(classes),\n",
    "        'img_scale': torch.stack(scales),\n",
    "        'img_size': torch.stack(sizes)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8d61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 모델\n",
    "def train_yolo(data_yaml, epochs=100):\n",
    "    print(\"\\n YOLOv5 학습 시작\")\n",
    "    model = YOLO(str(YOLO_WEIGHTS_FILE))\n",
    "    \n",
    "    results = model.train(\n",
    "        data=str(data_yaml),\n",
    "        epochs=epochs,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        name='yolov5_freshness',\n",
    "        device='0' if torch.cuda.is_available() else 'cpu',\n",
    "        patience=30,\n",
    "        workers=0,\n",
    "        project=str(RESULT_DIR)\n",
    "    )\n",
    "    \n",
    "    print(f\" YOLOv5 학습 완료\")\n",
    "    return model\n",
    "\n",
    "def test_yolo(model, data_yaml):\n",
    "    print(\"\\n YOLOv5 테스트셋 평가 시작\")\n",
    "    \n",
    "    test_metrics = model.val(\n",
    "        data=str(data_yaml),\n",
    "        split='test',\n",
    "        project=str(RESULT_DIR),\n",
    "        name='yolov5_test'\n",
    "    )\n",
    "    \n",
    "    yolo_test_metrics = {\n",
    "        'mAP50': float(test_metrics.box.map50),\n",
    "        'mAP50_95': float(test_metrics.box.map),\n",
    "        'precision': float(test_metrics.box.mp),\n",
    "        'recall': float(test_metrics.box.mr)\n",
    "    }\n",
    "    \n",
    "    print(f\"YOLOv5 테스트 완료\")\n",
    "    print(f\"  mAP@0.5: {yolo_test_metrics['mAP50']:.3f}\")\n",
    "    print(f\"  mAP@0.5:0.95: {yolo_test_metrics['mAP50_95']:.3f}\")\n",
    "    print(f\"  Precision: {yolo_test_metrics['precision']:.3f}\")\n",
    "    print(f\"  Recall: {yolo_test_metrics['recall']:.3f}\")\n",
    "    \n",
    "    # YOLO metrics 저장\n",
    "    yolo_metrics_path = RESULT_DIR / 'yolo_metrics.json'\n",
    "    with open(yolo_metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'summary': yolo_test_metrics\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"YOLO metrics 저장: {yolo_metrics_path}\")\n",
    "    \n",
    "    return yolo_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bfa3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO 형태변환\n",
    "def create_coco_annotations(splits, classes):    \n",
    "    coco_categories = []\n",
    "    for idx, name in enumerate(classes): \n",
    "        coco_categories.append({\n",
    "            \"id\": idx, \n",
    "            \"name\": name, \n",
    "            \"supercategory\": \"freshness\"\n",
    "        })\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        coco_images = []\n",
    "        coco_annotations = []\n",
    "        \n",
    "        coco_data = {\n",
    "            'info': {\n",
    "                \"description\": f\"Custom Dataset - {split} Set\",\n",
    "                \"version\": \"1.0\",\n",
    "                \"year\": 2025,\n",
    "                \"contributor\": \"Contributor\",\n",
    "                \"date_created\": \"2025/11/11\"\n",
    "            },\n",
    "            'licenses': [{\"id\": 0, \"name\": \"Unknown\", \"url\": \"\"}],\n",
    "            'categories': coco_categories,\n",
    "            'images': coco_images,\n",
    "            'annotations': coco_annotations\n",
    "        }\n",
    "        \n",
    "        ann_id = 0\n",
    "        \n",
    "        for img_id, item in enumerate(splits[split]):\n",
    "            try:\n",
    "                with open(str(item['image']), 'rb') as f:\n",
    "                    img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "                h, w = img.shape[:2]\n",
    "            except Exception as e:\n",
    "                print(f\"이미지 로드 실패 {item['image']}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            coco_data['images'].append({\n",
    "                'id': img_id,\n",
    "                'file_name': str(item['image']),\n",
    "                'width': w,\n",
    "                'height': h\n",
    "            })\n",
    "            \n",
    "            bbox = item['bbox']\n",
    "            coco_data['annotations'].append({\n",
    "                'id': ann_id,\n",
    "                'image_id': img_id,\n",
    "                'category_id': item['label'],\n",
    "                'bbox': [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]],\n",
    "                'area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]),\n",
    "                'iscrowd': 0\n",
    "            })\n",
    "            ann_id += 1\n",
    "        \n",
    "        anno_path = DATASET_EFFDET / f'coco_{split}.json'\n",
    "        with open(anno_path, 'w') as f:\n",
    "            json.dump(coco_data, f, indent=4)\n",
    "        \n",
    "        print(f\"COCO {split} annotations: {anno_path}\")\n",
    "    \n",
    "    return DATASET_EFFDET / 'coco_test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35405145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientDet 모델\n",
    "def train_efficientdet(splits, classes, epochs=100):\n",
    "    print(\"\\n EfficientDet 학습 시작\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_classes = len(classes)\n",
    "    \n",
    "    gt_anno_file = create_coco_annotations(splits, classes)\n",
    "\n",
    "    train_loader = DataLoader(EffDetDataset(splits['train']), batch_size=4,\n",
    "                             shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "    val_loader = DataLoader(EffDetDataset(splits['val']), batch_size=4,\n",
    "                           collate_fn=collate_fn, num_workers=0)\n",
    "    \n",
    "    config = get_efficientdet_config('tf_efficientdet_d0')\n",
    "    config.num_classes = num_classes\n",
    "    config.image_size = (512, 512)\n",
    "    \n",
    "    model = DetBenchTrain(EfficientDet(config, pretrained_backbone=True), config)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    max_patience = 30\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images = images.to(device)\n",
    "            targets = {k: v.to(device) for k, v in targets.items()}\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(images, targets)\n",
    "            loss = output['loss'] if isinstance(output, dict) else output\n",
    "            \n",
    "            if torch.isnan(loss):\n",
    "                print(\"NaN loss detected\")\n",
    "                continue\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = {k: v.to(device) for k, v in targets.items()}\n",
    "                output = model(images, targets)\n",
    "                loss = output['loss'] if isinstance(output, dict) else output\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss) \n",
    "        print(f\"Epoch {epoch+1}: Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
    "\n",
    "        if epoch == 0 or val_loss < best_loss:\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "            \n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': model.model.state_dict(),\n",
    "                'config': config\n",
    "            }, RESULT_DIR / 'efficientdet_best.pth')\n",
    "            print(f\"Saved (Loss: {best_loss:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= max_patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    print(f\"EfficientDet 학습 완료 (Best Loss: {best_loss:.4f})\")\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(\"EfficientDet Training Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULT_DIR / \"efficientdet_loss_curve.png\")\n",
    "    plt.close()\n",
    "    print(f\" EfficientDet 학습 곡선 저장됨: {RESULT_DIR / 'efficientdet_loss_curve.png'}\")\n",
    "\n",
    "    return model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3181a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_efficientdet_with_confusion_matrix(config, splits, classes, device):\n",
    "    print(\"\\n EfficientDet Confusion Matrix 평가 시작\")\n",
    "    \n",
    "    from effdet import EfficientDet, DetBenchPredict\n",
    "    \n",
    "    checkpoint_path = RESULT_DIR / 'efficientdet_best.pth'\n",
    "    if not checkpoint_path.exists():\n",
    "        print(\"모델 가중치 파일이 없습니다\")\n",
    "        return None\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    predictor = DetBenchPredict(net).to(device).eval()\n",
    "    \n",
    "    test_data = splits['test']\n",
    "    \n",
    "    y_true = []  \n",
    "    y_pred = []  \n",
    "    \n",
    "    def calculate_iou(box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - inter\n",
    "        \n",
    "        return inter / union if union > 0 else 0\n",
    "    \n",
    "    print(\"\\n 테스트 데이터 예측 중\")\n",
    "    for item in tqdm(test_data, desc=\"Predicting\"):\n",
    "        with open(item['image'], 'rb') as f:\n",
    "            img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        img_resized = cv2.resize(img, (512, 512))\n",
    "        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = predictor(img_tensor)\n",
    "        \n",
    "        gt_box = item['bbox']\n",
    "        gt_label = item['label']\n",
    "        y_true.append(gt_label)\n",
    "        \n",
    "        # 예측 결과 처리\n",
    "        best_pred_label = -1 \n",
    "        best_iou = 0\n",
    "        confidence_threshold = 0.3 \n",
    "        \n",
    "        if len(pred) > 0 and pred[0].shape[0] > 0:\n",
    "            pred_np = pred[0].cpu().numpy()\n",
    "            \n",
    "            for box in pred_np:\n",
    "                if box[4] < confidence_threshold:\n",
    "                    continue\n",
    "                \n",
    "                pred_box = [\n",
    "                    box[0] * w / 512, \n",
    "                    box[1] * h / 512,\n",
    "                    box[2] * w / 512, \n",
    "                    box[3] * h / 512\n",
    "                ]\n",
    "                pred_label = int(box[5]) if len(box) > 5 else 0\n",
    "                \n",
    "                iou = calculate_iou(gt_box, pred_box)\n",
    "                \n",
    "                if iou > best_iou and iou >= 0.5:\n",
    "                    best_iou = iou\n",
    "                    best_pred_label = pred_label\n",
    "        \n",
    "        if best_pred_label == -1:\n",
    "            if len(pred) > 0 and pred[0].shape[0] > 0:\n",
    "                pred_np = pred[0].cpu().numpy()\n",
    "                valid_preds = pred_np[pred_np[:, 4] >= confidence_threshold]\n",
    "                if len(valid_preds) > 0:\n",
    "                    best_idx = np.argmax(valid_preds[:, 4])\n",
    "                    best_pred_label = int(valid_preds[best_idx, 5])\n",
    "                else:\n",
    "                    if len(pred_np) > 0:\n",
    "                        best_idx = np.argmax(pred_np[:, 4])\n",
    "                        best_pred_label = int(pred_np[best_idx, 5])\n",
    "        \n",
    "        if best_pred_label == -1:\n",
    "            best_pred_label = len(classes)\n",
    "        \n",
    "        y_pred.append(best_pred_label)\n",
    "    \n",
    "    print(\"\\n Confusion Matrix 생성 중\")\n",
    "    \n",
    "    extended_classes = classes + ['No Detection']\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(extended_classes))))\n",
    "    \n",
    "    plt.figure(figsize=(max(12, len(extended_classes) * 0.8), max(10, len(extended_classes) * 0.7)))\n",
    "    \n",
    "    # 정규화된 Confusion Matrix\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=extended_classes, yticklabels=extended_classes,\n",
    "                cbar_kws={'label': 'Normalized Count'})\n",
    "    \n",
    "    plt.title('EfficientDet Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 저장\n",
    "    cm_path = RESULT_DIR / 'efficientdet_confusion_matrix_normalized.png'\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" 정규화된 Confusion Matrix 저장: {cm_path}\")\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(max(12, len(extended_classes) * 0.8), max(10, len(extended_classes) * 0.7)))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=extended_classes, yticklabels=extended_classes,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    \n",
    "    plt.title('EfficientDet Confusion Matrix (Count)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cm_count_path = RESULT_DIR / 'efficientdet_confusion_matrix_count.png'\n",
    "    plt.savefig(cm_count_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" 개수 Confusion Matrix 저장: {cm_count_path}\")\n",
    "    \n",
    "    print(\"\\n Classification Report:\")\n",
    "    print(\"=\"*70)\n",
    "    # No Detection 제외한 실제 클래스만으로 리포트 생성\n",
    "    valid_indices = [i for i, label in enumerate(y_pred) if label < len(classes)]\n",
    "    if valid_indices:\n",
    "        y_true_valid = [y_true[i] for i in valid_indices]\n",
    "        y_pred_valid = [y_pred[i] for i in valid_indices]\n",
    "        \n",
    "        # 실제로 예측된 클래스만 추출\n",
    "        unique_labels = sorted(list(set(y_true_valid + y_pred_valid)))\n",
    "        target_names_subset = [classes[i] for i in unique_labels if i < len(classes)]\n",
    "        \n",
    "        report = classification_report(y_true_valid, y_pred_valid, \n",
    "                                       labels=unique_labels,\n",
    "                                       target_names=target_names_subset, \n",
    "                                       zero_division=0)\n",
    "        print(report)\n",
    "        \n",
    "        # Classification Report 저장\n",
    "        report_path = RESULT_DIR / 'efficientdet_classification_report.txt'\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\n Classification Report 저장: {report_path}\")\n",
    "    \n",
    "    # 클래스별 정확도 계산\n",
    "    class_accuracies = {}\n",
    "    for i, class_name in enumerate(classes):\n",
    "        if cm[i].sum() > 0:\n",
    "            accuracy = cm[i, i] / cm[i].sum()\n",
    "            class_accuracies[class_name] = accuracy\n",
    "    \n",
    "    # 클래스별 정확도 시각화\n",
    "    if class_accuracies:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sorted_classes = sorted(class_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "        class_names = [x[0] for x in sorted_classes]\n",
    "        accuracies = [x[1] for x in sorted_classes]\n",
    "        \n",
    "        bars = plt.bar(range(len(class_names)), accuracies, color='skyblue', edgecolor='navy')\n",
    "        plt.xlabel('Class', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "        plt.title('EfficientDet: Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
    "        plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
    "        plt.ylim(0, 1.1)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # 값 표시\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        acc_path = RESULT_DIR / 'efficientdet_per_class_accuracy.png'\n",
    "        plt.savefig(acc_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\" 클래스별 정확도 그래프 저장: {acc_path}\")\n",
    "    \n",
    "    # 전체 정확도 계산\n",
    "    total_correct = np.trace(cm[:len(classes), :len(classes)])  # No Detection 제외\n",
    "    total_samples = cm[:len(classes), :].sum()\n",
    "    overall_accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "    \n",
    "    print(f\"\\n 전체 정확도: {overall_accuracy:.3f}\")\n",
    "    print(f\" 총 테스트 샘플: {len(y_true)}개\")\n",
    "    print(f\" 정확히 분류된 샘플: {total_correct}개\")\n",
    "    \n",
    "    # Confusion Matrix 데이터 저장\n",
    "    cm_data = {\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'classes': extended_classes,\n",
    "        'overall_accuracy': float(overall_accuracy),\n",
    "        'class_accuracies': {k: float(v) for k, v in class_accuracies.items()},\n",
    "        'total_samples': int(total_samples),\n",
    "        'correct_predictions': int(total_correct)\n",
    "    }\n",
    "    \n",
    "    cm_json_path = RESULT_DIR / 'efficientdet_confusion_matrix.json'\n",
    "    import json\n",
    "    with open(cm_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cm_data, f, indent=2, ensure_ascii=False)\n",
    "    print(f\" Confusion Matrix 데이터 저장: {cm_json_path}\")\n",
    "    \n",
    "    return cm, class_accuracies, overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e7377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_efficientdet(config, splits, classes):\n",
    "    print(\"\\n EfficientDet 테스트셋 평가 시작\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "\n",
    "    if COCO_AVAILABLE and len(splits['test']) > 0:\n",
    "        gt_anno_file = DATASET_EFFDET / 'coco_test.json'\n",
    "        effdet_test_metrics = evaluate_efficientdet_coco(config, splits, classes, device, gt_anno_file)\n",
    "    else:\n",
    "        effdet_test_metrics = evaluate_efficientdet_simple(config, splits, classes, device)\n",
    "\n",
    "    cm, class_accuracies, overall_accuracy = evaluate_efficientdet_with_confusion_matrix(\n",
    "        config, splits, classes, device\n",
    "    )\n",
    "    \n",
    "    effdet_test_metrics['overall_accuracy'] = overall_accuracy\n",
    "    effdet_test_metrics['class_accuracies'] = class_accuracies\n",
    "    \n",
    "    effdet_test_metrics.setdefault('mAP50', 0.0)\n",
    "    effdet_test_metrics.setdefault('mAP50_95', 0.0)\n",
    "    effdet_test_metrics.setdefault('precision', 0.0)\n",
    "    effdet_test_metrics.setdefault('recall', 0.0)\n",
    "    \n",
    "    print(f\"\\nEfficientDet 테스트 완료\")\n",
    "    print(f\" mAP@0.5: {effdet_test_metrics['mAP50']:.3f}\")\n",
    "    print(f\" mAP@0.5:0.95: {effdet_test_metrics['mAP50_95']:.3f}\")\n",
    "    print(f\" Precision: {effdet_test_metrics['precision']:.3f}\")\n",
    "    print(f\" Recall: {effdet_test_metrics['recall']:.3f}\")\n",
    "    print(f\" Overall Accuracy: {overall_accuracy:.3f}\")\n",
    "    \n",
    "    return effdet_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79c8ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_efficientdet_coco(config, splits, classes, device, gt_anno_file):\n",
    "    print(\"\\nEfficientDet COCO 평가 시작\")\n",
    "\n",
    "    checkpoint_path = RESULT_DIR / 'efficientdet_best.pth'\n",
    "    if not checkpoint_path.exists():\n",
    "        print(\"모델 가중치 파일이 없습니다:\", checkpoint_path)\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    bench = DetBenchPredict(net)\n",
    "    bench.eval()\n",
    "    bench.to(device)\n",
    "\n",
    "    coco_gt = COCO(str(gt_anno_file))\n",
    "\n",
    "    results = []\n",
    "    test_data = splits['test']\n",
    "\n",
    "    vis_dir = RESULT_DIR / 'efficientdet_test_predictions'\n",
    "    vis_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for img_id, item in enumerate(tqdm(test_data, desc=\"Predicting on Test Set\")):\n",
    "        img = cv2.imread(item['image'])\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img_rgb.shape[:2]\n",
    "\n",
    "        img_resized = cv2.resize(img_rgb, (512, 512))\n",
    "        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            detections = bench(img_tensor)\n",
    "\n",
    "        if detections is None or len(detections.shape) != 3:\n",
    "            continue\n",
    "\n",
    "        det = detections[0].cpu().numpy()\n",
    "        for i in range(det.shape[0]):\n",
    "            if det.shape[1] < 6:\n",
    "                continue\n",
    "            score = float(det[i, 4])\n",
    "            class_id = int(det[i, 5])\n",
    "            if score < 0.001:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = det[i, :4]\n",
    "            x1 = float(x1 * w / 512)\n",
    "            y1 = float(y1 * h / 512)\n",
    "            x2 = float(x2 * w / 512)\n",
    "            y2 = float(y2 * h / 512)\n",
    "            \n",
    "            if x2 <= x1 or y2 <= y1 or class_id < 0 or class_id >= len(classes):\n",
    "                continue\n",
    "\n",
    "            results.append({\n",
    "                'image_id': int(img_id),\n",
    "                'category_id': int(class_id),\n",
    "                'bbox': [x1, y1, x2 - x1, y2 - y1],\n",
    "                'score': float(score)\n",
    "            })\n",
    "\n",
    "    if not results:\n",
    "        print(\"예측 결과 없음\")\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "\n",
    "    pred_file = RESULT_DIR / 'coco_test_predictions.json'\n",
    "    with open(pred_file, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    try:\n",
    "        coco_dt = coco_gt.loadRes(str(pred_file))\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        coco_eval.summarize()\n",
    "\n",
    "        metrics = {\n",
    "            'mAP50_95': float(coco_eval.stats[0]),\n",
    "            'mAP50': float(coco_eval.stats[1]),\n",
    "            'precision': float(coco_eval.stats[0]),\n",
    "            'recall': float(coco_eval.stats[8])\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"COCO 평가 중 오류: {e}\")\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "    \n",
    "        # EfficientDet metrics 저장\n",
    "    effdet_metrics_path = RESULT_DIR / 'efficientdet_metrics.json'\n",
    "    with open(effdet_metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'summary': metrics\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"EfficientDet metrics 저장: {effdet_metrics_path}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551c4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_efficientdet_simple(config, splits, classes, device):\n",
    "    print(\"\\n EfficientDet Simple 평가 중\")\n",
    "    \n",
    "    checkpoint_path = RESULT_DIR / 'efficientdet_best.pth'\n",
    "    if not checkpoint_path.exists():\n",
    "        print(\"모델 가중치 파일이 없습니다\")\n",
    "        return {'mAP50': 0.0, 'mAP50_95': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    predictor = DetBenchPredict(net).to(device).eval()\n",
    "    \n",
    "    test_data = splits['test']\n",
    "    \n",
    "    def calculate_iou(box1, box2):\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - inter\n",
    "        \n",
    "        return inter / union if union > 0 else 0\n",
    "    \n",
    "    correct_50 = 0\n",
    "    all_ious = []\n",
    "    \n",
    "    for item in tqdm(test_data, desc=\"Evaluating\"):\n",
    "        with open(item['image'], 'rb') as f:\n",
    "            img = cv2.imdecode(np.frombuffer(f.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        img_resized = cv2.resize(img, (512, 512))\n",
    "        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = predictor(img_tensor)\n",
    "        \n",
    "        gt_box = item['bbox']\n",
    "        gt_label = item['label']\n",
    "        \n",
    "        best_iou = 0\n",
    "        \n",
    "        if len(pred) > 0 and pred[0].shape[0] > 0:\n",
    "            pred_np = pred[0].cpu().numpy()\n",
    "            for box in pred_np:\n",
    "                if box[4] < 0.1:\n",
    "                    continue\n",
    "                \n",
    "                pred_box = [\n",
    "                    box[0] * w / 512, box[1] * h / 512,\n",
    "                    box[2] * w / 512, box[3] * h / 512\n",
    "                ]\n",
    "                pred_label = int(box[5]) if len(box) > 5 else 0\n",
    "                \n",
    "                if pred_label == gt_label:\n",
    "                    iou = calculate_iou(gt_box, pred_box)\n",
    "                    best_iou = max(best_iou, iou)\n",
    "        \n",
    "        all_ious.append(best_iou)\n",
    "        if best_iou >= 0.5:\n",
    "            correct_50 += 1\n",
    "    \n",
    "    total = len(test_data)\n",
    "    mAP_50 = correct_50 / total if total > 0 else 0\n",
    "    \n",
    "    mAP_50_95_sum = 0\n",
    "    for thresh in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:\n",
    "        correct = sum([1 for iou in all_ious if iou >= thresh])\n",
    "        mAP_50_95_sum += (correct / total if total > 0 else 0)\n",
    "    mAP_50_95 = mAP_50_95_sum / 10\n",
    "    \n",
    "    metrics = {\n",
    "        'mAP50': float(mAP_50),\n",
    "        'mAP50_95': float(mAP_50_95),\n",
    "        'precision': float(mAP_50),\n",
    "        'recall': float(mAP_50)\n",
    "    }\n",
    "\n",
    "        # EfficientDet metrics 저장\n",
    "    effdet_metrics_path = RESULT_DIR / 'efficientdet_metrics.json'\n",
    "    with open(effdet_metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'summary': metrics\n",
    "        }, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"EfficientDet metrics 저장: {effdet_metrics_path}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95c4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_comparison(yolo_metrics, effdet_metrics, title_suffix=\"\"):\n",
    "    metrics_names = ['mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall']\n",
    "    yolo_values = [\n",
    "        yolo_metrics['mAP50'],\n",
    "        yolo_metrics['mAP50_95'],\n",
    "        yolo_metrics['precision'],\n",
    "        yolo_metrics['recall']\n",
    "    ]\n",
    "    effdet_values = [\n",
    "        effdet_metrics['mAP50'],\n",
    "        effdet_metrics['mAP50_95'],\n",
    "        effdet_metrics['precision'],\n",
    "        effdet_metrics['recall']\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, yolo_values, width, label='YOLOv5', color='#FF6B6B')\n",
    "    bars2 = ax.bar(x + width/2, effdet_values, width, label='EfficientDet', color='#4ECDC4')\n",
    "    \n",
    "    ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'YOLOv5 vs EfficientDet Performance Comparison{title_suffix}', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(metrics_names)\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = 'performance_comparison_test.png' if title_suffix else 'performance_comparison.png'\n",
    "    plt.savefig(RESULT_DIR / filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n 비교 그래프 저장: {RESULT_DIR / filename}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d04b7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_table(yolo_metrics, effdet_metrics, title=\"성능 비교\"):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"{title:^70}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Metric':<20} {'YOLOv5':<15} {'EfficientDet':<15} {'Difference':<15}\")\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{'mAP@0.5':<20} {yolo_metrics['mAP50']:<15.3f} {effdet_metrics['mAP50']:<15.3f} {yolo_metrics['mAP50']-effdet_metrics['mAP50']:+.3f}\")\n",
    "    print(f\"{'mAP@0.5:0.95':<20} {yolo_metrics['mAP50_95']:<15.3f} {effdet_metrics['mAP50_95']:<15.3f} {yolo_metrics['mAP50_95']-effdet_metrics['mAP50_95']:+.3f}\")\n",
    "    print(f\"{'Precision':<20} {yolo_metrics['precision']:<15.3f} {effdet_metrics['precision']:<15.3f} {yolo_metrics['precision']-effdet_metrics['precision']:+.3f}\")\n",
    "    print(f\"{'Recall':<20} {yolo_metrics['recall']:<15.3f} {effdet_metrics['recall']:<15.3f} {yolo_metrics['recall']-effdet_metrics['recall']:+.3f}\")\n",
    "    \n",
    "    if yolo_metrics['mAP50'] > effdet_metrics['mAP50']:\n",
    "        winner = \"YOLOv5\"\n",
    "        diff = yolo_metrics['mAP50'] - effdet_metrics['mAP50']\n",
    "    elif effdet_metrics['mAP50'] > yolo_metrics['mAP50']:\n",
    "        winner = \"EfficientDet\"\n",
    "        diff = effdet_metrics['mAP50'] - yolo_metrics['mAP50']\n",
    "    else:\n",
    "        winner = \"동점\"\n",
    "        diff = 0\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    if winner != \"동점\":\n",
    "        print(f\"{winner}가 {diff:.3f}만큼 더 높은 mAP@0.5를 달성했습니다!\")\n",
    "    else:\n",
    "        print(f\"두 모델이 동일한 성능을 보였습니다!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33765e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_final():\n",
    "    yolo_metrics_path = RESULT_DIR / \"yolo_metrics.json\"\n",
    "    effdet_metrics_path = RESULT_DIR / \"efficientdet_metrics.json\"\n",
    "    \n",
    "    if not yolo_metrics_path.exists() or not effdet_metrics_path.exists():\n",
    "        print(\"metrics 파일이 없습니다. 평가가 완료되지 않았습니다.\")\n",
    "        return\n",
    "\n",
    "    with open(yolo_metrics_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        yolo_data = json.load(f)\n",
    "    with open(effdet_metrics_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        effdet_data = json.load(f)\n",
    "\n",
    "    yolo_summary = yolo_data.get(\"summary\", {})\n",
    "    effdet_summary = effdet_data.get(\"summary\", {})\n",
    "\n",
    "    metrics_names = [\"mAP@0.5\", \"mAP@0.5:0.95\", \"Precision\", \"Recall\"]\n",
    "    metric_keys = [\"mAP50\", \"mAP50_95\", \"precision\", \"recall\"]\n",
    "\n",
    "    yolo_scores = [yolo_summary.get(k, 0) for k in metric_keys]\n",
    "    effdet_scores = [effdet_summary.get(k, 0) for k in metric_keys]\n",
    "\n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, yolo_scores, width, label=\"YOLOv5\", color='red', alpha=0.8)\n",
    "    plt.bar(x + width/2, effdet_scores, width, label=\"EfficientDet\", color='blue', alpha=0.8)\n",
    "\n",
    "    plt.xticks(x, metrics_names, fontsize=11)\n",
    "    plt.ylabel(\"Score\", fontsize=12, fontweight='bold')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(\"YOLOv5 vs EfficientDet 최종 성능 비교\", fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 값 표시\n",
    "    for i, (y_score, e_score) in enumerate(zip(yolo_scores, effdet_scores)):\n",
    "        if y_score > 0:\n",
    "            plt.text(i - width/2, y_score, f'{y_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "        if e_score > 0:\n",
    "            plt.text(i + width/2, e_score, f'{e_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = RESULT_DIR / \"final_comparison_graph.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n 최종 성능 비교 그래프 저장 완료 → {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d7b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"YOLOv5 vs EfficientDet 성능 비교 (실제 테스트 데이터)\")\n",
    "    \n",
    "    # 1. 데이터 전처리\n",
    "    print(\"\\n 1단계 데이터 전처리\")\n",
    "    print(f\"   원천데이터 경로: {JSON_DIR}\")\n",
    "    \n",
    "    splits, classes = preprocess_data()\n",
    "    if not classes:\n",
    "        print(\"데이터셋 없음\")\n",
    "        return\n",
    "    \n",
    "    if len(splits['test']) == 0:\n",
    "        print(\"\\n 오류: 테스트 데이터가 없습니다!\")\n",
    "        print(f\"   다음 경로를 확인해주세요:\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n클래스 목록 ({len(classes)}개):\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        print(f\"  {i}: {cls}\")\n",
    "    \n",
    "    # 2. YOLOv5 학습\n",
    "    print(\"2단계 YOLOv5 학습\")\n",
    "    prepare_yolo_dataset(splits, classes)\n",
    "    yolo_model = train_yolo(DATASET_YOLO / 'data.yaml', epochs=100)\n",
    "\n",
    "    # 3. EfficientDet 학습\n",
    "    print(\"3단계 EfficientDet 학습\")\n",
    "    effdet_model, effdet_config = train_efficientdet(splits, classes, epochs=100)\n",
    "    \n",
    "    # 4. 테스트셋 평가\n",
    "    print(\"4단계 실제 테스트 데이터로 최종 평가\")\n",
    "    print(f\"   테스트 이미지 수: {len(splits['test'])}개\")\n",
    "    \n",
    "    # YOLOv5 테스트\n",
    "    yolo_test_metrics = test_yolo(yolo_model, DATASET_YOLO / 'data.yaml')\n",
    "    \n",
    "    # EfficientDet 테스트\n",
    "    effdet_test_metrics = test_efficientdet(effdet_config, splits, classes)\n",
    "    \n",
    "    # 5. 결과 비교 및 시각화\n",
    "    print(\"【5단계】 결과 비교 및 시각화\")\n",
    "    \n",
    "    winner = print_results_table(yolo_test_metrics, effdet_test_metrics, \"실제 테스트 데이터 최종 성능 비교\")\n",
    "    visualize_comparison(yolo_test_metrics, effdet_test_metrics, \" (Real Test Data)\")\n",
    "    \n",
    "    # 최종 비교 그래프\n",
    "    compare_models_final()\n",
    "    \n",
    "    # 6. 결과 저장\n",
    "    results_summary = {\n",
    "        'dataset_info': {\n",
    "            'train_source': 'data/raw (80%)',\n",
    "            'val_source': 'data/raw (20%)',\n",
    "            'test_source': 'data/test_data (별도)',\n",
    "            'num_train': len(splits['train']),\n",
    "            'num_val': len(splits['val']),\n",
    "            'num_test': len(splits['test']),\n",
    "            'classes': classes\n",
    "        },\n",
    "        'yolo_test': yolo_test_metrics,\n",
    "        'efficientdet_test': effdet_test_metrics,\n",
    "        'winner': winner\n",
    "    }\n",
    "    \n",
    "    with open(RESULT_DIR / 'final_test_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # 7. 간단한 요약 그래프\n",
    "    labels = ['mAP@0.5', 'mAP@0.5:0.95']\n",
    "    yolo_scores = [yolo_test_metrics['mAP50'], yolo_test_metrics['mAP50_95']]\n",
    "    effdet_scores = [effdet_test_metrics['mAP50'], effdet_test_metrics['mAP50_95']]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(x - width/2, yolo_scores, width, label='YOLOv5', color='red', alpha=0.8)\n",
    "    plt.bar(x + width/2, effdet_scores, width, label='EfficientDet', color='blue', alpha=0.8)\n",
    "\n",
    "    plt.ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    plt.title('Real Test Data: YOLOv5 vs EfficientDet', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x, labels, fontsize=11)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    for i, (y_score, e_score) in enumerate(zip(yolo_scores, effdet_scores)):\n",
    "        plt.text(i - width/2, y_score, f'{y_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(i + width/2, e_score, f'{e_score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULT_DIR / 'test_summary_graph.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 최종 출력\n",
    "    print(\"모든 작업 완료!\")\n",
    "    print(f\"\\n 결과 저장 위치: {RESULT_DIR.resolve()}\")\n",
    "    print(f\"\\n 생성된 파일:\")\n",
    "    print(f\"  YOLOv5 테스트: yolov5_test/\")\n",
    "    print(f\"  EfficientDet 테스트 예측: efficientdet_test_predictions/\")\n",
    "    print(f\"  성능 비교 그래프: performance_comparison_test.png\")\n",
    "    print(f\"  최종 비교 그래프: final_comparison_graph.png\")\n",
    "    print(f\"  요약 그래프: test_summary_graph.png\")\n",
    "    print(f\"  결과 JSON: final_test_results.json\")\n",
    "    print(f\"  YOLO metrics: yolo_metrics.json\")\n",
    "    print(f\"  EfficientDet metrics: efficientdet_metrics.json\")\n",
    "    \n",
    "    print(f\"\\n 데이터 구성:\")\n",
    "    print(f\"  - 학습: {len(splits['train'])}개 (원천데이터 80%)\")\n",
    "    print(f\"  - 검증: {len(splits['val'])}개 (원천데이터 20%)\")\n",
    "    print(f\"  - 테스트: {len(splits['test'])}개 (별도 실제 데이터)\")\n",
    "    \n",
    "    print(f\"\\n 최종 승자: {winner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5937462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv5 vs EfficientDet 성능 비교 (실제 테스트 데이터)\n",
      "\n",
      " 1단계 데이터 전처리\n",
      "   원천데이터 경로: c:\\miniproject\\friut\\data\\raw\\json_labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train: 100%|██████████| 720/720 [00:10<00:00, 70.55it/s]\n",
      "Loading val: 100%|██████████| 90/90 [00:01<00:00, 71.74it/s]\n",
      "Loading test: 100%|██████████| 90/90 [00:01<00:00, 66.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train=720, val=90, test=90\n",
      "\n",
      "클래스 목록 (9개):\n",
      "  0: 사과_특\n",
      "  1: 배_특\n",
      "  2: 사과_보통\n",
      "  3: 감_특\n",
      "  4: 배_보통\n",
      "  5: 사과_상\n",
      "  6: 배_상\n",
      "  7: 감_보통\n",
      "  8: 감_상\n",
      "2단계 YOLOv5 학습\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLO train: 100%|██████████| 720/720 [00:16<00:00, 43.76it/s]\n",
      "YOLO val: 100%|██████████| 90/90 [00:02<00:00, 44.05it/s]\n",
      "YOLO test: 100%|██████████| 90/90 [00:02<00:00, 44.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO 데이터셋 준비 완료: c:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\n",
      "\n",
      " YOLOv5 학습 시작\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'c:\\miniproject\\friut\\processed\\results_comparison\\yolov5su.pt': 100% ━━━━━━━━━━━━ 17.7MB 10.2MB/s 1.7s1.6s<0.1s\n",
      "New https://pypi.org/project/ultralytics/8.3.227 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.225  Python-3.9.25 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=c:\\miniproject\\friut\\processed\\results_comparison\\yolov5su.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov5_freshness, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=c:\\miniproject\\friut\\processed\\results_comparison, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\miniproject\\friut\\processed\\results_comparison\\yolov5_freshness, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
      "YOLOv5s summary: 153 layers, 9,125,675 parameters, 9,125,659 gradients, 24.1 GFLOPs\n",
      "\n",
      "Transferred 421/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 18.15.3 MB/s, size: 169.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\\labels\\train... 720 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 720/720 683.8it/s 1.1s0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 16.52.2 MB/s, size: 147.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\\labels\\val... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 661.3it/s 0.1s0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\\labels\\val.cache\n",
      "Plotting labels to C:\\miniproject\\friut\\processed\\results_comparison\\yolov5_freshness\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\miniproject\\friut\\processed\\results_comparison\\yolov5_freshness\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      3.83G     0.5782      2.751      1.295         47        640: 100% ━━━━━━━━━━━━ 45/45 1.8it/s 25.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.5s1.1s\n",
      "                   all         90         90      0.324      0.895       0.45      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      3.41G     0.2535      1.556          1         53        640: 100% ━━━━━━━━━━━━ 45/45 2.0it/s 22.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.303      0.785      0.477      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      3.42G      0.241      1.413     0.9848         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.8s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.345      0.868       0.59      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      3.43G     0.2465      1.272     0.9827         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s1.0s\n",
      "                   all         90         90      0.646      0.397       0.51      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      3.41G     0.2263      1.249     0.9666         45        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.335       0.85      0.595      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      3.43G     0.2176      1.171     0.9692         50        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90       0.47      0.822      0.642      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      3.43G     0.2087      1.128     0.9675         52        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s0.9s\n",
      "                   all         90         90      0.516      0.781      0.677      0.648\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      3.43G     0.1815      1.096     0.9492         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.468      0.929      0.736      0.673\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      3.41G     0.1935      1.093     0.9471         47        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.433      0.944      0.759      0.714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      3.42G     0.2094      1.073     0.9637         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.569      0.814      0.651      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      3.42G      0.179      1.017     0.9453         56        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.1it/s 1.4s1.0s\n",
      "                   all         90         90      0.545      0.883      0.711      0.708\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      3.43G     0.1756     0.9791     0.9419         40        640: 100% ━━━━━━━━━━━━ 45/45 2.0it/s 22.0s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.0it/s 1.5s1.0s\n",
      "                   all         90         90      0.606      0.922      0.804      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      3.41G     0.1724      1.008     0.9408         47        640: 100% ━━━━━━━━━━━━ 45/45 2.0it/s 22.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.1it/s 1.4s1.0s\n",
      "                   all         90         90      0.512      0.944      0.728       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      3.42G     0.1676     0.9663      0.939         56        640: 100% ━━━━━━━━━━━━ 45/45 2.0it/s 22.0s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s0.9s\n",
      "                   all         90         90      0.513       0.98      0.834      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      3.42G      0.174     0.8973     0.9434         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s0.9s\n",
      "                   all         90         90      0.551      0.885      0.806      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      3.42G     0.1671     0.9013     0.9429         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.563      0.907      0.824      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      3.41G     0.1511     0.9063     0.9273         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.596      0.775      0.771      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      3.42G     0.1476     0.9088     0.9284         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.571      0.881      0.821      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      3.42G      0.145     0.8885     0.9295         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.452      0.885      0.752      0.742\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      3.42G     0.1448        0.9     0.9387         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.648      0.861      0.811      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      3.41G      0.143     0.8778     0.9209         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.592      0.702       0.72      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      3.42G      0.152     0.8675     0.9361         47        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.571      0.761      0.789      0.751\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      3.43G     0.1401     0.8387     0.9238         54        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.727      0.865      0.867      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      3.43G     0.1393     0.7752     0.9241         53        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.534      0.919      0.816      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      3.41G     0.1359     0.8135     0.9175         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.669      0.903      0.926      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      3.43G     0.1283      0.736       0.92         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.712      0.906      0.885      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      3.42G     0.1331     0.7634     0.9205         44        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.839      0.852      0.946      0.946\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      3.43G     0.1352     0.7654     0.9195         50        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.655      0.889      0.906      0.906\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      3.41G     0.1285      0.722     0.9236         47        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.745      0.834      0.918      0.914\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      3.42G      0.134     0.7173     0.9249         53        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.705      0.875      0.883      0.874\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      3.42G     0.1364     0.7329     0.9336         42        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.799      0.933      0.987       0.98\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      3.43G     0.1261      0.697     0.9243         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.823      0.887      0.941      0.927\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      3.41G     0.1194      0.691     0.9229         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.643      0.891      0.916      0.893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      3.42G     0.1234      0.651     0.9105         43        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.684      0.921      0.913        0.9\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      3.42G     0.1271     0.6543     0.9162         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.792      0.887      0.921      0.911\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      3.42G      0.112     0.6713     0.9128         45        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90       0.87      0.837       0.95      0.943\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      3.41G     0.1081     0.6651     0.9108         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.807      0.889      0.949      0.943\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      3.42G     0.1089     0.6664     0.9123         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.892      0.915      0.977      0.977\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      3.42G      0.115     0.6309     0.9124         45        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.836      0.893      0.947      0.947\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      3.43G     0.1102     0.6005     0.9089         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.646      0.844      0.902      0.897\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      3.41G     0.1044     0.6127     0.9149         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.842      0.904      0.979      0.978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      3.43G     0.1106     0.5834     0.9196         47        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.824      0.908      0.966      0.965\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      3.42G     0.1114     0.5915     0.9192         41        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.861      0.902      0.975      0.967\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      3.42G     0.1012     0.5518     0.9132         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90       0.87      0.931      0.975      0.968\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      3.41G     0.1014     0.5216     0.9109         44        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.922      0.928      0.981      0.976\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      3.42G     0.1077     0.5571     0.9106         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.854        0.9      0.969      0.967\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      3.42G     0.1017     0.5083     0.9102         54        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s0.9s\n",
      "                   all         90         90      0.912      0.941      0.973      0.973\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      3.42G    0.09834     0.5199     0.9041         54        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.958      0.938      0.992      0.978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      3.41G     0.1036     0.4951     0.9138         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.895      0.908      0.979      0.977\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      3.43G      0.102     0.5104     0.9189         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.926      0.849      0.992      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      3.43G     0.1019     0.5098     0.9044         43        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.953      0.958      0.986      0.957\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      3.42G     0.0996     0.5247     0.9094         50        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90       0.92      0.956      0.983      0.969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      3.41G    0.09924     0.4625     0.9097         53        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.925      0.947      0.988      0.963\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      3.43G    0.09761     0.4931     0.9025         43        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s0.9s\n",
      "                   all         90         90      0.852      0.976      0.987      0.974\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      3.43G     0.0977     0.4814     0.9124         36        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.878      0.886      0.972      0.969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      3.42G    0.09813      0.486     0.9036         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.891      0.968      0.991      0.986\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      3.41G    0.09416     0.4493     0.9071         55        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.954      0.932      0.979      0.972\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      3.43G    0.08666     0.4312     0.9008         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.901      0.906      0.989      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      3.42G    0.09265     0.4521     0.9061         38        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.887      0.983      0.987      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      3.42G    0.08967     0.4195     0.9043         42        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.918      0.954      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      3.41G    0.08041     0.4382     0.8951         53        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.932       0.97      0.994      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      3.43G    0.09379     0.4148     0.9103         44        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.924      0.972      0.995      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      3.43G     0.0869     0.4373     0.9045         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.936      0.976      0.988      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      3.42G     0.0885     0.4102     0.9037         47        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.3s0.9s\n",
      "                   all         90         90      0.927      0.887      0.975      0.967\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      3.41G    0.08896     0.4349     0.9093         43        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.921      0.883      0.972      0.972\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      3.42G    0.08412     0.4431     0.9033         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.943      0.983      0.991      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      3.42G    0.08672     0.4185     0.9036         42        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.965      0.981      0.987      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      3.43G    0.08518     0.4061     0.9048         53        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.945      0.941      0.989      0.985\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      3.41G    0.08198     0.3506     0.9069         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.971      0.974      0.987      0.987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      3.42G    0.07872     0.3538     0.9049         48        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.929      0.948      0.984      0.984\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      3.42G    0.07929     0.3556      0.894         38        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.961      0.989      0.994      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      3.43G    0.07724     0.3667     0.8935         52        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.977       0.96      0.991       0.99\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      3.41G    0.07645     0.3413     0.9024         53        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.916      0.944      0.991      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      3.42G     0.0784     0.3659     0.9003         61        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.913      0.938      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      3.42G    0.07787     0.3517     0.8985         44        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.986      0.964      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      3.43G    0.07616     0.3386     0.9009         47        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.921      0.978      0.992      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      3.41G    0.07906     0.3125     0.9033         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.987      0.936      0.991      0.988\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      3.43G    0.07513     0.3225     0.8916         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.965      0.964      0.993      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      3.42G    0.07785      0.293     0.9013         54        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.982      0.976      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      3.41G    0.07323      0.308     0.8981         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.2it/s 1.4s0.9s\n",
      "                   all         90         90      0.972      0.928      0.989      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      3.41G     0.0777     0.3291     0.9008         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.971      0.972      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      3.42G    0.06963     0.2962     0.8906         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.981       0.97      0.993      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      3.42G    0.06887     0.2968      0.899         49        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.972      0.968      0.994      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      3.43G    0.06769     0.2818     0.8994         46        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.986      0.955      0.994      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      3.41G    0.06924     0.2969     0.9025         50        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.971      0.993      0.994      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      3.43G    0.07038     0.2836     0.9046         54        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.961      0.982      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      3.43G     0.0657     0.2601     0.8986         51        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.976      0.955      0.989      0.989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      3.42G    0.06102     0.2712     0.9038         45        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.986      0.979      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      3.41G    0.06793       0.27      0.897         55        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.1it/s 1.4s1.0s\n",
      "                   all         90         90      0.984      0.953      0.991      0.991\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      3.42G    0.06578     0.2746     0.8991         50        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 21.5s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.981      0.962      0.995      0.995\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      3.41G    0.04575     0.3472     0.9074         16        640: 100% ━━━━━━━━━━━━ 45/45 2.1it/s 20.9s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.981      0.956      0.993      0.993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      3.41G    0.04083     0.2617     0.9067         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.9s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90       0.99      0.981      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      3.39G    0.03953     0.2073     0.9005         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.988      0.978      0.994      0.994\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      3.42G    0.03772     0.2403     0.8949         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.987      0.952      0.992      0.992\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100       3.4G    0.03681     0.1802     0.9071         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.8s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.987      0.974      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100       3.4G    0.03626     0.1768     0.9005         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.989      0.978      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      3.39G    0.03359     0.1421      0.904         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.983      0.983      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100       3.4G    0.03291     0.1669      0.901         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.991      0.976      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100       3.4G    0.03218     0.1793     0.8952         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.994      0.977      0.995      0.995\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100       3.4G    0.03349      0.149      0.894         16        640: 100% ━━━━━━━━━━━━ 45/45 2.2it/s 20.8s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.3it/s 1.3s0.9s\n",
      "                   all         90         90      0.991       0.98      0.995      0.995\n",
      "\n",
      "100 epochs completed in 0.652 hours.\n",
      "Optimizer stripped from C:\\miniproject\\friut\\processed\\results_comparison\\yolov5_freshness\\weights\\last.pt, 18.5MB\n",
      "Optimizer stripped from C:\\miniproject\\friut\\processed\\results_comparison\\yolov5_freshness\\weights\\best.pt, 18.5MB\n",
      "\n",
      "Validating C:\\miniproject\\friut\\processed\\results_comparison\\yolov5_freshness\\weights\\best.pt...\n",
      "Ultralytics 8.3.225  Python-3.9.25 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.7it/s 1.7s1.1s\n",
      "                   all         90         90      0.991       0.98      0.995      0.995\n",
      "                  _          9          9       0.99          1      0.995      0.995\n",
      "                   _         12         12          1      0.874      0.995      0.995\n",
      "                 _         11         11      0.994          1      0.995      0.995\n",
      "                   _          6          6      0.988          1      0.995      0.995\n",
      "                  _         13         13          1      0.944      0.995      0.995\n",
      "                  _          5          5      0.985          1      0.995      0.995\n",
      "                   _         10         10      0.971          1      0.995      0.995\n",
      "                  _         11         11      0.993          1      0.995      0.995\n",
      "                   _         13         13      0.994          1      0.995      0.995\n",
      "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\miniproject\\friut\\processed\\results_comparison\\yolov5_freshness\u001b[0m\n",
      " YOLOv5 학습 완료\n",
      "3단계 EfficientDet 학습\n",
      "\n",
      " EfficientDet 학습 시작\n",
      "COCO train annotations: c:\\miniproject\\friut\\processed\\preprocessed_data\\efficientdet\\coco_train.json\n",
      "COCO val annotations: c:\\miniproject\\friut\\processed\\preprocessed_data\\efficientdet\\coco_val.json\n",
      "COCO test annotations: c:\\miniproject\\friut\\processed\\preprocessed_data\\efficientdet\\coco_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.num_batches_tracked, bn2.bias, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Epoch 1/100: 100%|██████████| 180/180 [00:47<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train=0.5364, Val=0.3654\n",
      "Saved (Loss: 0.3654)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train=0.3137, Val=0.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train=0.2882, Val=0.9017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train=0.2730, Val=0.3153\n",
      "Saved (Loss: 0.3153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train=0.2592, Val=0.4326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train=0.2624, Val=0.2875\n",
      "Saved (Loss: 0.2875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train=0.2593, Val=0.2410\n",
      "Saved (Loss: 0.2410)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train=0.2470, Val=0.3173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train=0.2523, Val=0.2353\n",
      "Saved (Loss: 0.2353)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train=0.2342, Val=0.2281\n",
      "Saved (Loss: 0.2281)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train=0.2753, Val=0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train=0.2490, Val=0.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train=0.2323, Val=0.2503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 180/180 [00:47<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train=0.2246, Val=0.2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train=0.2156, Val=0.2089\n",
      "Saved (Loss: 0.2089)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train=0.2082, Val=0.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train=0.1995, Val=0.2348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train=0.1855, Val=0.2055\n",
      "Saved (Loss: 0.2055)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train=0.1750, Val=0.3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train=0.1698, Val=0.2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train=0.1615, Val=0.1954\n",
      "Saved (Loss: 0.1954)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train=0.1380, Val=0.1612\n",
      "Saved (Loss: 0.1612)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train=0.1205, Val=0.1418\n",
      "Saved (Loss: 0.1418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train=0.1166, Val=0.1318\n",
      "Saved (Loss: 0.1318)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train=0.1167, Val=0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train=0.1093, Val=0.1953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train=0.1106, Val=0.1158\n",
      "Saved (Loss: 0.1158)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train=0.1035, Val=0.0966\n",
      "Saved (Loss: 0.0966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train=0.0823, Val=0.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train=0.0812, Val=0.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train=0.0668, Val=0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train=0.0823, Val=0.1867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train=0.0641, Val=0.0975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train=0.0806, Val=0.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train=0.0492, Val=0.1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train=0.0565, Val=0.0700\n",
      "Saved (Loss: 0.0700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train=0.0451, Val=0.3236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train=0.0703, Val=0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train=0.0445, Val=0.0597\n",
      "Saved (Loss: 0.0597)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train=0.0308, Val=0.0740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train=0.0371, Val=0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train=0.0268, Val=0.0790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train=0.0259, Val=0.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train=0.0157, Val=0.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train=0.0079, Val=0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train=0.0189, Val=0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train=0.0353, Val=0.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train=0.0166, Val=0.0498\n",
      "Saved (Loss: 0.0498)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train=0.0184, Val=0.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train=0.0227, Val=0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train=0.0106, Val=0.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train=0.0023, Val=0.0669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train=0.0034, Val=0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train=0.0065, Val=0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train=0.0017, Val=0.0497\n",
      "Saved (Loss: 0.0497)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train=0.0338, Val=0.0980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train=0.0075, Val=0.0455\n",
      "Saved (Loss: 0.0455)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train=0.0074, Val=0.1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train=0.0057, Val=0.0834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train=0.0081, Val=0.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Train=0.0092, Val=0.1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Train=0.0038, Val=0.0335\n",
      "Saved (Loss: 0.0335)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Train=0.0022, Val=0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Train=0.0076, Val=0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Train=0.0027, Val=0.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Train=0.0104, Val=0.0960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Train=0.0035, Val=0.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Train=0.0014, Val=0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Train=0.0006, Val=0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Train=0.0006, Val=0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Train=0.0016, Val=0.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Train=0.0021, Val=0.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Train=0.0018, Val=0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Train=0.0005, Val=0.0624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Train=0.0002, Val=0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Train=0.0002, Val=0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Train=0.0002, Val=0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 180/180 [00:47<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Train=0.0003, Val=0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Train=0.0003, Val=0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Train=0.0051, Val=0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train=0.0017, Val=0.0621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Train=0.0003, Val=0.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Train=0.0003, Val=0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Train=0.0002, Val=0.0519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Train=0.0002, Val=0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Train=0.0002, Val=0.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Train=0.0001, Val=0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 180/180 [00:46<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Train=0.0002, Val=0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 180/180 [00:47<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train=0.0001, Val=0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train=0.0001, Val=0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train=0.0002, Val=0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 180/180 [00:46<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train=0.0002, Val=0.0474\n",
      "Early stopping at epoch 92\n",
      "EfficientDet 학습 완료 (Best Loss: 0.0335)\n",
      " EfficientDet 학습 곡선 저장됨: c:\\miniproject\\friut\\processed\\results_comparison\\efficientdet_loss_curve.png\n",
      "4단계 실제 테스트 데이터로 최종 평가\n",
      "   테스트 이미지 수: 90개\n",
      "\n",
      " YOLOv5 테스트셋 평가 시작\n",
      "Ultralytics 8.3.225  Python-3.9.25 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv5s summary (fused): 84 layers, 9,115,019 parameters, 0 gradients, 23.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 20.06.4 MB/s, size: 214.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\\labels\\test... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 596.6it/s 0.2s0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\miniproject\\friut\\processed\\preprocessed_data\\yolov5\\labels\\test.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 6/6 1.6it/s 3.7s0.3ss\n",
      "                   all         90         90      0.993      0.995      0.995      0.994\n",
      "                  _         16         16      0.996          1      0.995      0.995\n",
      "                   _         10         10      0.994          1      0.995      0.995\n",
      "                 _         11         11      0.995          1      0.995      0.995\n",
      "                   _         10         10      0.992          1      0.995      0.995\n",
      "                  _         10         10          1      0.951      0.995      0.995\n",
      "                  _          8          8      0.991          1      0.995      0.995\n",
      "                   _         12         12      0.995          1      0.995      0.983\n",
      "                  _          8          8      0.992          1      0.995      0.995\n",
      "                   _          5          5      0.984          1      0.995      0.995\n",
      "Speed: 2.4ms preprocess, 8.4ms inference, 0.1ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\miniproject\\friut\\processed\\results_comparison\\yolov5_test\u001b[0m\n",
      "YOLOv5 테스트 완료\n",
      "  mAP@0.5: 0.995\n",
      "  mAP@0.5:0.95: 0.994\n",
      "  Precision: 0.993\n",
      "  Recall: 0.995\n",
      "YOLO metrics 저장: c:\\miniproject\\friut\\processed\\results_comparison\\yolo_metrics.json\n",
      "\n",
      " EfficientDet 테스트셋 평가 시작\n",
      "\n",
      "EfficientDet COCO 평가 시작\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on Test Set: 100%|██████████| 90/90 [00:06<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.867\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.884\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.884\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.884\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.884\n",
      "EfficientDet metrics 저장: c:\\miniproject\\friut\\processed\\results_comparison\\efficientdet_metrics.json\n",
      "\n",
      " EfficientDet Confusion Matrix 평가 시작\n",
      "\n",
      " 테스트 데이터 예측 중\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 90/90 [00:06<00:00, 14.94it/s]\n",
      "C:\\Users\\smart\\AppData\\Local\\Temp\\ipykernel_19492\\159491433.py:104: RuntimeWarning: invalid value encountered in divide\n",
      "  cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion Matrix 생성 중\n",
      " 정규화된 Confusion Matrix 저장: c:\\miniproject\\friut\\processed\\results_comparison\\efficientdet_confusion_matrix_normalized.png\n",
      " 개수 Confusion Matrix 저장: c:\\miniproject\\friut\\processed\\results_comparison\\efficientdet_confusion_matrix_count.png\n",
      "\n",
      " Classification Report:\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        사과_특       0.00      0.00      0.00        16\n",
      "         배_특       0.88      0.70      0.78        10\n",
      "       사과_보통       0.53      0.91      0.67        11\n",
      "         감_특       1.00      0.90      0.95        10\n",
      "        배_보통       0.80      0.80      0.80        10\n",
      "        사과_상       0.53      1.00      0.70         8\n",
      "         배_상       0.79      0.92      0.85        12\n",
      "        감_보통       0.89      1.00      0.94         8\n",
      "         감_상       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.69      0.80      0.73        90\n",
      "weighted avg       0.64      0.73      0.67        90\n",
      "\n",
      "\n",
      " Classification Report 저장: c:\\miniproject\\friut\\processed\\results_comparison\\efficientdet_classification_report.txt\n",
      " 클래스별 정확도 그래프 저장: c:\\miniproject\\friut\\processed\\results_comparison\\efficientdet_per_class_accuracy.png\n",
      "\n",
      " 전체 정확도: 0.733\n",
      " 총 테스트 샘플: 90개\n",
      " 정확히 분류된 샘플: 66개\n",
      " Confusion Matrix 데이터 저장: c:\\miniproject\\friut\\processed\\results_comparison\\efficientdet_confusion_matrix.json\n",
      "\n",
      "EfficientDet 테스트 완료\n",
      " mAP@0.5: 0.871\n",
      " mAP@0.5:0.95: 0.867\n",
      " Precision: 0.867\n",
      " Recall: 0.884\n",
      " Overall Accuracy: 0.733\n",
      "【5단계】 결과 비교 및 시각화\n",
      "\n",
      "======================================================================\n",
      "                         실제 테스트 데이터 최종 성능 비교                          \n",
      "======================================================================\n",
      "\n",
      "Metric               YOLOv5          EfficientDet    Difference     \n",
      "----------------------------------------------------------------------\n",
      "mAP@0.5              0.995           0.871           +0.124\n",
      "mAP@0.5:0.95         0.994           0.867           +0.127\n",
      "Precision            0.993           0.867           +0.126\n",
      "Recall               0.995           0.884           +0.110\n",
      "\n",
      "======================================================================\n",
      "YOLOv5가 0.124만큼 더 높은 mAP@0.5를 달성했습니다!\n",
      "======================================================================\n",
      "\n",
      " 비교 그래프 저장: c:\\miniproject\\friut\\processed\\results_comparison\\performance_comparison_test.png\n",
      "\n",
      " 최종 성능 비교 그래프 저장 완료 → c:\\miniproject\\friut\\processed\\results_comparison\\final_comparison_graph.png\n",
      "모든 작업 완료!\n",
      "\n",
      " 결과 저장 위치: C:\\miniproject\\friut\\processed\\results_comparison\n",
      "\n",
      " 생성된 파일:\n",
      "  YOLOv5 테스트: yolov5_test/\n",
      "  EfficientDet 테스트 예측: efficientdet_test_predictions/\n",
      "  성능 비교 그래프: performance_comparison_test.png\n",
      "  최종 비교 그래프: final_comparison_graph.png\n",
      "  요약 그래프: test_summary_graph.png\n",
      "  결과 JSON: final_test_results.json\n",
      "  YOLO metrics: yolo_metrics.json\n",
      "  EfficientDet metrics: efficientdet_metrics.json\n",
      "\n",
      " 데이터 구성:\n",
      "  - 학습: 720개 (원천데이터 80%)\n",
      "  - 검증: 90개 (원천데이터 20%)\n",
      "  - 테스트: 90개 (별도 실제 데이터)\n",
      "\n",
      " 최종 승자: YOLOv5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d97aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
